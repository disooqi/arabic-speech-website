{% extends "layout.html" %}

{% block content %}
<div class="col-md-8 blog-main">
    <br/>
    <br/>
    <nav>
  <div class="nav nav-tabs" id="nav-tab" role="tablist">
    <a class="nav-item nav-link active" id="nav-asr-tab" data-toggle="tab" href="#nav-asr" role="tab" aria-controls="nav-asr" aria-selected="true"><small>Automatic Speech Recognition</small></a>
    <a class="nav-item nav-link" id="nav-adi-tab" data-toggle="tab" href="#nav-adi" role="tab" aria-controls="nav-adi" aria-selected="false"><small>Arabic Dialect Identifcation</small></a>
    <a class="nav-item nav-link" id="nav-tts-tab" data-toggle="tab" href="#nav-tts" role="tab" aria-controls="nav-tts" aria-selected="false"><small>Text To Speech</small></a>
    <a class="nav-item nav-link" id="nav-lm-tab" data-toggle="tab" href="#nav-lm" role="tab" aria-controls="nav-lm" aria-selected="false"><small>Language Model</small></a>
  </div>
</nav>
<div class="tab-content" id="nav-tabContent">
  <div class="tab-pane fade show active" id="nav-asr" role="tabpanel" aria-labelledby="nav-asr-tab">
  <div class="blog-post">
                        <br/>
                        <h4 class="">Automatic Speech Recognition</h4>
                        <br/>
                        <p>Automatic Speech Recognition (ASR) is defined as the process of realising acoustic speech audio into
                            a corresponding word sequence, which is the word sequence that is as close as possible to what a
                            human could transcribe. The best start for ASR is the <a
                                    href="http://htk.eng.cam.ac.uk/docs/docs.shtml">HTKbook</a>.</p>
                        <p>You can also learn a lot from <a href="http://kaldi-asr.org/">kaldi</a>. Kaldi is a toolkit for
                            speech recognition written in C++ and
                            licensed under the Apache License v2.0. Kaldi is intended for use by speech recognition researchers.
                        </p>
                        <p>You can learn more about Automatic Speech Recognition from the brief <a href="{{ url_for('publications')}}">list of relevant publication</a> we provide.</p>
                        <hr>

                    </div>
  
  </div>
  <div class="tab-pane fade" id="nav-adi" role="tabpanel" aria-labelledby="nav-adi-tab">
  <div class="blog-post">
                        <br/>
                        <h4 class="">Arabic Dialect Identifcation</h4>
                        <br/>
                        <!-- /.blog-post<p>Arabic dialects are sufficiently diverse to the extent that one can argue to describe them as different languages rather than dialects of the same language. Thus, automatically identifying the input dialect can greatly improve ASR.</p>
                        <p>It can be argued that a language is a dialect with an army and navy. If we take this perspective into consideration, we can describe the different Arabic dialects as different languages. However, Arabic today is a language with different dialects and different armies!</p>
                        <p>Dialect identification can be regarded as a special case of language recognition. However, dialect identification is a harder problem since there is no single view of how many spoken dialects there are in Arabic. You can learn about the latest research in Arabic Dialect Identification (ADI) <a href="{{ url_for('publications')}}">here</a>.</p>
                         -->
                        <p>Arabic language has several spoken dialects. There are four major dialects for Arabic, including Egyptian, Gulf, Levantine and North African in addition to modern standard Arabic (MSA) which is the official language in Arabic speaking countries. Sometimes these dialects are significantly different to be considered as different languages rather than dialects of the same language. Thus, automatically identifying the input dialect from the speech signal has been an interesting research problem both on its own and to improve automatic speech recognition (ASR) [1].</p>
                        <p>Approaches to dialect identification are closely related to those of language recognition. These include Gaussian mixture models, the phonotactic approach and phone recognition [2], the i-vector combined with dimensionality reduction [3] and more recently deep learning techniques [4-7]. Arabic dialect identification has been also closely associated with improving dialectal  Arabic ASR interesting work has been done in the context of the GALE project [8] and recent thesis [9]. In spite of this advances Arabic dialect recognition remains a challenging problem and several special sessions and contests have been organized around the subject [10]. These include good pointers to many techniques and data sets. Also there are various repositories [11-13] can be a good start for having an experimental setup.</p>
                        <small>
                            <p style="margin-bottom:0;"> [1] A. Ali, et al. "Automatic dialect detection in Arabic broadcast speech." in Interspeech 2016.</p> 
                            <p style="margin-bottom:0;"> [2] Marc A. Zissman, “A comparison of four approaches to automatic language identification of telephone speech,” in IEEE Transactions on Speech and Audio Processing, vol. 4, no. 1, Jan 1996.</p> 
                            <p style="margin-bottom:0;"> [3] N. Dehak, P.A. Torres-Carrasquillo, D. Reynolds and R. Dehak, “Language recognition via i-vectors and dimensionality reduction,” in Interspeech 2011.</p> 
                            <p style="margin-bottom:0;"> [4] O. Ghahabi, A. Bonafonte, J. Hernando and A. Moreno, “Deep neural networks for i-vector language identification of short utterances in cars,” in Interspeech 2016.</p> 
                            <p style="margin-bottom:0;"> [5] S. Shon, A. Ali, and J. Glass. "MIT-QCRI Arabic dialect identification system for the 2017 multi-genre broadcast challenge." Automatic Speech Recognition and Understanding Workshop (ASRU), 2017.</p> 
                            <p style="margin-bottom:0;"> [6] M. Najafian, et al. "Exploiting convolutional neural networks for phonotactic based dialect identification." in ICASSP 2018.</p> 
                            <p style="margin-bottom:0;"> [7] S. Shon, A. Ali, and J. Glass. "Convolutional Neural Network and Language Embeddings for End-to-End Dialect Recognition." Proc. Odyssey 2018 The Speaker and Language Recognition Workshop. 2018.</p> 
                            <p style="margin-bottom:0;"> [8] F. Biadsy, J. Hirschberg and N. Habash, “Spoken Arabic dialect identification using phonotactic modeling, in Proceedings of EACL workshop on computational approaches to Semitic languages, 2009.</p> 
                            <p style="margin-bottom:0;"> [9] A. Ali. Multi-dialect Arabic broadcast speech recognition. PhD thesis, The University of Edinburgh, 2018.</p> 
                            <p style="margin-bottom:0;"> [10] Zampieri, Marcos, et al. "Language Identification and Morphosyntactic Tagging: The Second VarDial Evaluation Campaign." Proceedings of the Fifth Workshop on NLP for Similar Languages, Varieties and Dialects. Association for Computational Linguistics, 2018.</p> 
                            <p style="margin-bottom:0;"> [11] https://github.com/qcri/dialectID/</p> 
                            <p style="margin-bottom:0;"> [12] https://github.com/swshon/dialectID_e2e</p> 
                            <p style="margin-bottom:0;"> [13] https://github.com/swshon/dialectID_siam </p> 
                        </small>
                         
                    </div><!-- /.blog-post -->
    </div>
  <div class="tab-pane fade" id="nav-tts" role="tabpanel" aria-labelledby="nav-tts-tab">
  <div class="blog-post">
                        <br/>
                        <h4 class="">Text To Speech</h4>
                        <br/>
                        <p>The Text to Speech (TTS) technology aims to convert a sequence of words into speech.  Since Modern Standard Arabic (MSA) is written without diacritics, the first step to develop an Arabic TTS engine [1] is to restore the diacritics of each word in the text [2][3][4]. The diacritized text is then passed to a phonetic transcription module to generate the phoneme sequence for each phrase [5]. The phone sequence and phonological features are used to synthesis the speech output (i. e. sound).  The synthesizer historically was either concatenative [1] or parametric [6]. Recently, End-to-End synthesizers based on neural networks are developed [7][8][9].</p>
                        <small>
                            <p style="margin-bottom:0;">  [1] Hifny, Yasser, et al. "ArabTalk®: An Implementation for Arabic Text To Speech System."The proceedings of the 4th Conference on Language Engineering. 2004.  </p>
                            <p style="margin-bottom:0;">  [2] Rashwan, Mohsen AA, et al. "A stochastic Arabic diacritizer based on a hybrid of factorized and unfactorized textual features."IEEE Transactions on Audio, Speech, and Language Processing 19.1 (2011): 166-175. </p>
                            <p style="margin-bottom:0;"> [3] Darwish, Kareem, Hamdy Mubarak, and Ahmed Abdelali. "Arabic diacritization: Stats, rules, and hacks."Proceedings of the Third Arabic Natural Language Processing Workshop. 2017.</p>
                            <p style="margin-bottom:0;"> [4] Hifny, Yasser. "Hybrid LSTM/MaxEnt Networks for Arabic Syntactic Diacritics Restoration."IEEE Signal Processing Letters 25.10 (2018): 1515-1519.</p>
                            <p style="margin-bottom:0;"> [5] https://github.com/nawarhalabi/Arabic-Phonetiser</p>
                            <p style="margin-bottom:0;"> [6] Abdel-Hamid, Ossama, Sherif Mahdy Abdou, and Mohsen Rashwan. "Improving Arabic HMM based speech synthesis quality." Ninth International Conference on Spoken Language Processing. 2006.</p>
                            <p style="margin-bottom:0;"> [7] Ping, Wei, et al. "Deep voice 3: Scaling text-to-speech with convolutional sequence learning." (2018).</p>
                            <p style="margin-bottom:0;"> [8] Wang, Yuxuan, et al. "Tacotron: Towards end-to-end speech synthesis." arXiv preprint arXiv:1703.10135 (2017).</p>
                            <p style="margin-bottom:0;"> [9] https://github.com/youssefsharief/arabic-tacotron-tts</p> 
                        </small>
                    </div><!-- /.blog-post -->
  </div>
  <div class="tab-pane fade" id="nav-lm" role="tabpanel" aria-labelledby="nav-lm-tab">
  <div class="blog-post">
                        <br/>
                        <h4 class="">Language Model </h4>
                        <br/>
                        <p>Language Model is ...</p>
                    </div><!-- /.blog-post -->
                    
  </div>
</div>
</div>
{% endblock content %}
